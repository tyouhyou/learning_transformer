{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n03e3Q6ku1Hl"
      },
      "source": [
        "This is just a note for my learning of transformer, referred to articles and codes from\n",
        "\n",
        "- https://www.tensorflow.org/tutorials/text/transformer\n",
        "- https://github.com/MorvanZhou/NLP-Tutorials/blob/master/transformer.py\n",
        "- https://zhuanlan.zhihu.com/p/347904940\n",
        "\n",
        "All credits go to the above authors.\n",
        "\n",
        "The notes / comments are my understanding at this moment, please correct me if they are wrong."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8r9Ua_Pb3MBk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tokenizer\n",
        "Tokenize the inputting sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Tokenizer():\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocabulary          : np.array # List[str]\n",
        "        ):\n",
        "        self.voc = vocabulary\n",
        "\n",
        "    def __call__(self, sequence_batch : np.array) -> np.array:\n",
        "        \"\"\"\n",
        "        Tokenize the sequence\n",
        "        @arg\n",
        "            sequence_batch: batch of sequences inputting.\n",
        "                            starts with <BOS> and ends with <EOS>\n",
        "                            the list wrapped in np.array is List[List[str]]\n",
        "        @return\n",
        "            np.array, shape [batch, sequence_size]\n",
        "        \"\"\"\n",
        "        # TODO 1. insert <bos> and <eos> to sequence and padding ?\n",
        "        #      2. performance issue ?\n",
        "        tk = np.array([[self.voc.index(s) for s in seq] for seq in sequence_batch])\n",
        "        return tk\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLZMFACy23IX"
      },
      "source": [
        "## Embedding And Positional encoding\n",
        "\n",
        "If input is [batch_size, sequence_length], after embedding, we get a tensor of [batch_size, sequence_length, embedding_dimension].\n",
        "* The batch size is the number of batch to transformer, in human's language, the number of sentences.\n",
        "* The sequence length is the size of samples in one inputting, that is, the words number in one sentence. Since not all sentences have same length, this value should be the possible longest length.\n",
        "* The embedding dimention is decided by Word2Vec. For transformer make it 512."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "NJm_IvUN268q"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding():\n",
        "    def __init__(\n",
        "        self, \n",
        "        vocabulary_size         : int,\n",
        "        max_sequence_length     : int,\n",
        "        embed_dimension         : int = 512,\n",
        "        padding                 : bool = False, # in case for encoder if masking padding is desired\n",
        "        ):\n",
        "        \"\"\"\n",
        "        @arg\n",
        "        embed_dimension:\n",
        "            The dimmention of embedding, or feature number.\n",
        "        sequence_length:\n",
        "            The words size in one sentence. \n",
        "            If there has 8 words in one sentence, the value is 8. \n",
        "            However, since it's impossible for all sentences have same size, \n",
        "            this value should be set to a size of the possibe longest sentence.\n",
        "        vocabulary:\n",
        "            The vocabulary table.\n",
        "        \"\"\"\n",
        "        \n",
        "        self.s_size = max_sequence_length\n",
        "        self.v_size = vocabulary_size\n",
        "        self.e_size = embed_dimension\n",
        "        \n",
        "        self.embedding = keras.layers.Embedding(\n",
        "            input_dim=self.v_size,\n",
        "            output_dim=self.e_size,\n",
        "            input_length=self.s_size,\n",
        "            embeddings_initializer=tf.initializers.RandomNormal(0., 0.01),\n",
        "            mask_zero=True\n",
        "        )\n",
        "        \n",
        "        # make positional encoding array\n",
        "        positional_encoding = np.array(\n",
        "            [\n",
        "            [pos / np.power(10000, 2 * i / self.e_size) for i in range(self.e_size)]\n",
        "            if (not (padding and 0 != pos)) else \n",
        "            np.zeros(self.e_size) for pos in np.arange(self.s_size) \n",
        "            ])\n",
        "\n",
        "        # The formula for calculating the positional encoding is as follows:\n",
        "        # PE(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
        "        # PE(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
        "\n",
        "        positional_encoding[0:, 0::2] = np.sin(positional_encoding[0:, 0::2])\n",
        "        positional_encoding[0:, 1::2] = np.cos(positional_encoding[0:, 1::2])\n",
        "        positional_encoding = positional_encoding[None, :, :]\n",
        "        self.positional_encoding = tf.cast(positional_encoding, dtype=tf.float32)\n",
        "        \n",
        "    def __call__(self, batch : np.array) -> tf.Tensor:\n",
        "        \"\"\"\n",
        "        The batch should be tokenized, which is expected to be the output of Tokenizer.\n",
        "        The type of batch is np.array, shape -> [batch_size, sequence_szie]\n",
        "\n",
        "        TODO: ?? embeding * tf.math.sqrt() ??\n",
        "        \"\"\"\n",
        "        return self.embedding(batch) + self.positional_encoding[:, :self.s_size, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 4, 3), dtype=float32, numpy=\n",
              "array([[[ 0.00576795, -0.0003815 ,  0.00452463],\n",
              "        [ 0.00479912,  0.00535715, -0.00688996],\n",
              "        [ 0.00795193, -0.02192049, -0.00800237],\n",
              "        [ 0.01102773, -0.00101122, -0.01441262]],\n",
              "\n",
              "       [[ 0.00795193, -0.02192049, -0.00800237],\n",
              "        [ 0.01102773, -0.00101122, -0.01441262],\n",
              "        [ 0.01640142, -0.00770752, -0.00339737],\n",
              "        [ 0.00479912,  0.00535715, -0.00688996]]], dtype=float32)>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pe = PositionalEmbedding(5, 4, 3, padding=True)\n",
        "rst = pe(np.array([[0,1,2,3],[2,3,4,1]]))\n",
        "rst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scfth32m3Aej"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cN__Pa7V3IOq"
      },
      "outputs": [],
      "source": [
        "class encoder(keras.layers.Layer):\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zLwJO4E2wXL"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbtQ2y3r2ze7"
      },
      "outputs": [],
      "source": [
        "class decoder():\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ALe7aa_3O6p"
      },
      "source": [
        "## Transfomer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwwvHDAOfHiT"
      },
      "outputs": [],
      "source": [
        "class transformer(keras.Model):\n",
        "    def __init__(self):\n",
        "       pass"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "learning_transformer_tensorflow.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
